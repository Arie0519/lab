{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3808,
     "status": "ok",
     "timestamp": 1710218211953,
     "user": {
      "displayName": "介川友喜",
      "userId": "17499639928451463634"
     },
     "user_tz": -540
    },
    "id": "-9VZTe45csf0"
   },
   "outputs": [],
   "source": [
    "# 必要なライブラリのインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Normalization\n",
    "from keras.layers import PositionEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 6990200809883498685\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 6750236672\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 12651911330773846834\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1710220252253,
     "user": {
      "displayName": "介川友喜",
      "userId": "17499639928451463634"
     },
     "user_tz": -540
    },
    "id": "Mx30c97cas5g"
   },
   "outputs": [],
   "source": [
    "# パラメータの設定\n",
    "EMBED_DIM = 256\n",
    "NUM_HEADS = 8\n",
    "FF_DIM = 4 * EMBED_DIM\n",
    "BATCH_SIZE = 1024\n",
    "STEPS_PER_EPOCH = 10\n",
    "PATIENCE = 40\n",
    "EPOCHS = 10\n",
    "l2_reg = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1710220254010,
     "user": {
      "displayName": "介川友喜",
      "userId": "17499639928451463634"
     },
     "user_tz": -540
    },
    "id": "CuYmiwlOawcn"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(dataset):\n",
    "    # 特徴量とラベルの選択・前処理\n",
    "    data = dataset.iloc[:, list(range(4, 12)) + [29] + list(range(19, 27))]\n",
    "    label = dataset[['x_2', 'y_2']]\n",
    "\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1710220257569,
     "user": {
      "displayName": "介川友喜",
      "userId": "17499639928451463634"
     },
     "user_tz": -540
    },
    "id": "ox9Z458fcwcc"
   },
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "train_dataset = pd.read_csv(R'C:/Users/sukegawa/Desktop/study/datasets/tinvfp/tinvfp_train0.csv')\n",
    "logdir = R'C:/Users/sukegawa/Desktop/study/logs/test'\n",
    "modelname = R'C:/Users/sukegawa/Desktop/study/model/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1710220260498,
     "user": {
      "displayName": "介川友喜",
      "userId": "17499639928451463634"
     },
     "user_tz": -540
    },
    "id": "Hg30IVrbdD3N"
   },
   "outputs": [],
   "source": [
    "# 現在のエポック数,損失の表示\n",
    "class CustomMetricsCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Epoch {epoch + 1}/{self.params['epochs']} - LOSS: {logs['loss']:.4f} - Val_LOSS: {logs['val_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1710220262505,
     "user": {
      "displayName": "介川友喜",
      "userId": "17499639928451463634"
     },
     "user_tz": -540
    },
    "id": "UaYCuDjtXKWQ"
   },
   "outputs": [],
   "source": [
    "# MultiHeadSelfAttentionクラス\n",
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\")\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "        attention, _ = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output\n",
    "\n",
    "# TransformerBlockクラス\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg)),\n",
    "             layers.Dense(embed_dim, kernel_regularizer=keras.regularizers.l2(l2_reg))]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(0.1)\n",
    "        self.dropout2 = layers.Dropout(0.1)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, training=training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "# PositionEmbeddingクラス\n",
    "class PositionEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, embed_dim):\n",
    "        super(PositionEmbedding, self).__init__()\n",
    "        self.pos_emb = layers.Embedding(input_dim=sequence_length, output_dim=embed_dim)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, x):\n",
    "        positions = tf.range(start=0, limit=tf.shape(x)[-1], delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        x = x[..., tf.newaxis]\n",
    "        x = tf.tile(x, [1, 1, self.embed_dim])\n",
    "        return x + positions\n",
    "\n",
    "# TransformerModelクラス\n",
    "class TransformerModel(models.Model):\n",
    "    def __init__(self, sequence_length, embed_dim, num_heads, ff_dim, normalizer):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.normalizer = normalizer\n",
    "        self.pos_emb = PositionEmbedding(sequence_length, embed_dim)\n",
    "        self.transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "        self.global_average_pooling = layers.GlobalAveragePooling1D()\n",
    "        self.dropout = layers.Dropout(0.1)\n",
    "        self.dense1 = layers.Dense(20, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l2_reg))\n",
    "        self.dense2 = layers.Dense(2, kernel_regularizer=keras.regularizers.l2(l2_reg))  # 2次元座標の出力\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.normalizer(inputs)\n",
    "        x = self.pos_emb(x)\n",
    "        x = self.transformer_block(x)\n",
    "        x = self.global_average_pooling(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRANSTrainer:\n",
    "    def __init__(self):\n",
    "        self.embed_dim = EMBED_DIM\n",
    "        self.num_heads = NUM_HEADS\n",
    "        self.ff_dim = FF_DIM\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.steps_per_epoch = STEPS_PER_EPOCH\n",
    "        self.patience = PATIENCE\n",
    "        self.epochs = EPOCHS\n",
    "\n",
    "    def setupnormalizer(self, data):\n",
    "        # 標準化レイヤーの設定\n",
    "        normalizer = Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(data))\n",
    "        return normalizer\n",
    "\n",
    "    def build_model(self, data, normalizer):\n",
    "        # 学習率スケジューリング\n",
    "        lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "            0.001,\n",
    "            decay_steps=STEPS_PER_EPOCH*1000,\n",
    "            decay_rate=0.9,\n",
    "            staircase=False)\n",
    "\n",
    "        # データの長さを指定\n",
    "        sequence_length = data.shape[1]\n",
    "\n",
    "        # モデルの構築\n",
    "        model = TransformerModel(sequence_length, self.embed_dim, self.num_heads, self.ff_dim, normalizer)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss=\"mean_squared_error\", metrics=[\"mean_squared_error\"])\n",
    "        return model\n",
    "\n",
    "    def train(self, train_dataset):\n",
    "        data, label = preprocess_data(train_dataset)\n",
    "\n",
    "        normalizer = self.setupnormalizer(data)\n",
    "\n",
    "        model = self.build_model(data, normalizer)\n",
    "\n",
    "        if not model.built:\n",
    "            sample_input = data[:1]  # 最初の1サンプルを使用\n",
    "            model(sample_input)\n",
    "        \n",
    "\n",
    "        # Tensorboardの設定\n",
    "        log_dir = logdir    # ログディレクトリの指定\n",
    "        tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "        # モデルのサマリーを表示\n",
    "        model.summary()\n",
    "\n",
    "        model.fit(\n",
    "            data,\n",
    "            label,\n",
    "            validation_split=0.2,\n",
    "            batch_size=self.batch_size,\n",
    "            epochs=self.epochs,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=self.patience),\n",
    "                CustomMetricsCallback(),\n",
    "            ],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # モデルの保存\n",
    "        model.save(modelname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54354,
     "status": "ok",
     "timestamp": 1710220330846,
     "user": {
      "displayName": "介川友喜",
      "userId": "17499639928451463634"
     },
     "user_tz": -540
    },
    "id": "MGX8nW5rdTRc",
    "outputId": "4e3650b9-53ec-41ae-8c77-b05b2e1a6a8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  multiple                 35        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " position_embedding (Positio  multiple                 4352      \n",
      " nEmbedding)                                                     \n",
      "                                                                 \n",
      " transformer_block (Transfor  multiple                 789760    \n",
      " merBlock)                                                       \n",
      "                                                                 \n",
      " global_average_pooling1d (G  multiple                 0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  5140      \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 799,329\n",
      "Trainable params: 799,294\n",
      "Non-trainable params: 35\n",
      "_________________________________________________________________\n",
      "Epoch 1/10 - LOSS: 2.7174 - Val_LOSS: 1.5001\n",
      "Epoch 2/10 - LOSS: 0.8874 - Val_LOSS: 0.8995\n",
      "Epoch 3/10 - LOSS: 0.5461 - Val_LOSS: 0.4441\n",
      "Epoch 4/10 - LOSS: 0.3904 - Val_LOSS: 0.2936\n",
      "Epoch 5/10 - LOSS: 0.3071 - Val_LOSS: 0.1971\n",
      "Epoch 6/10 - LOSS: 0.2564 - Val_LOSS: 0.2165\n",
      "Epoch 7/10 - LOSS: 0.2206 - Val_LOSS: 0.1484\n",
      "Epoch 8/10 - LOSS: 0.1998 - Val_LOSS: 0.1050\n",
      "Epoch 9/10 - LOSS: 0.1835 - Val_LOSS: 0.1184\n",
      "Epoch 10/10 - LOSS: 0.1735 - Val_LOSS: 0.0928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, multi_head_self_attention_layer_call_fn, multi_head_self_attention_layer_call_and_return_conditional_losses, layer_normalization_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sukegawa/Desktop/study/model/test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sukegawa/Desktop/study/model/test\\assets\n"
     ]
    }
   ],
   "source": [
    "# TRANSTrainerインスタンスの作成と訓練の実行\n",
    "trainer = TRANSTrainer()\n",
    "trainer.train(train_dataset)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
